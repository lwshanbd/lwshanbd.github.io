---
---

@inproceedings{shan2020lcfi,
  abbr={LLVM},
  title={LCFI: A Fault Injection Tool for Studying Lossy Compression Error Propagation in HPC Programs},
  author={Shan, Baodi and Shamji, Aabid and Tian, Jiannan and Li, Guanpeng and Tao, Dingwen},
  booktitle={2020 IEEE International Conference on Big Data (Big Data)},
  pages={2708--2715},
  year={2020},
  organization={IEEE},
  selected={true},
  bibtex_show={true},
  pdf={lcfi.pdf},
}

@InProceedings{10.1007/978-3-031-15922-0_2,
abbr="LLVM/OpenMP",
author="Lu, Wenbin
and Shan, Baodi
and Raut, Eric
and Meng, Jie
and Araya-Polo, Mauricio
and Doerfert, Johannes
and Malik, Abid M.
and Chapman, Barbara",
editor="Klemm, Michael
and de Supinski, Bronis R.
and Klinkenberg, Jannis
and Neth, Brandon",
title="Towards Efficient Remote OpenMP Offloading",
booktitle="OpenMP in a Modern World: From Multi-device Support to Meta Programming",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="17--31",
abstract="On modern heterogeneous HPC systems, the most popular way to realize distributed computation is the hybrid programming model of MPI+X (X being OpenMP/CUDA/etc.), as it has been proven to perform well with various scientific applications. However, application developers prefer to use a single coherent programming model over a hybrid model, as maintainability and portability decrease per additional model. Recent work [14] has shown that the OpenMP device offloading model could be used to program distributed accelerator-based HPC systems with minimal changes to the application.",
isbn="978-3-031-15922-0",
bibtex_show={true},
selected={true},
pdf={iwomp22.pdf},
}

@inproceedings{10.1145/3582514.3582519,
abbr="LLVM/OpenMP",
author = {Shan, Baodi and Araya-Polo, Mauricio and Malik, Abid M. and Chapman, Barbara},
title = {MPI-Based Remote OpenMP Offloading: A More Efficient and Easy-to-Use Implementation},
year = {2023},
isbn = {9798400701153},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3582514.3582519},
doi = {10.1145/3582514.3582519},
booktitle = {Proceedings of the 14th International Workshop on Programming Models and Applications for Multicores and Manycores},
pages = "50--59",
numpages = {10},
keywords = {OpenMP, distributed computing, GPGPU},
location = {Montreal, QC, Canada},
series = {PMAM'23},
bibtex_show={true},
selected={true},
pdf={pmam23.pdf},
}

@INPROCEEDINGS{10596372,
abbr="LLVM/OpenMP",
  author={Shan, Baodi and Araya-Polo, Mauricio},
  booktitle={2024 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={Evaluation of Programming Models and Performance for Stencil Computation on GPGPUs}, 
  year={2024},
  volume={},
  number={},
  pages={1178-1180},
  keywords={Solid modeling;Distributed processing;Three-dimensional displays;Computational modeling;High performance computing;Conferences;Graphics processing units;stencil computation;GPGPU;CUDA;OpenMP},
  doi={10.1109/IPDPSW63119.2024.00198}}


@InProceedings{10.1007/978-3-031-72567-8_5,
abbr="LLVM/OpenMP",
author="Shan, Baodi
and Araya-Polo, Mauricio
and Chapman, Barbara",
editor="Espinosa, Alexis
and Klemm, Michael
and de Supinski, Bronis R.
and Cytowski, Maciej
and Klinkenberg, Jannis",
title="Towards a Scalable and Efficient PGAS-Based Distributed OpenMP",
booktitle="Advancing OpenMP for Future Accelerators",
year="2024",
publisher="Springer Nature Switzerland",
address="Cham",
pages="64--78",
abstract="MPI+X has been the de facto standard for distributed memory parallel programming. It is widely used primarily as an explicit two-sided communication model, which often leads to complex and error-prone code. Alternatively, PGAS model utilizes efficient one-sided communication and more intuitive communication primitives. In this paper, we present a novel approach that integrates PGAS concepts into the OpenMP programming model, leveraging the LLVM compiler infrastructure and the GASNet-EX communication library. Our model addresses the complexity associated with traditional MPI+OpenMP programming models while ensuring excellent performance and scalability. We evaluate our approach using a set of micro-benchmarks and application kernels on two distinct platforms: Ookami from Stony Brook University and NERSC Perlmutter. The results demonstrate that DiOMP achieves superior bandwidth and lower latency compared to MPI+OpenMP, up to {\$}{\$}25{\backslash}{\%}{\$}{\$}25{\%}higher bandwidth and down to {\$}{\$}45{\backslash}{\%}{\$}{\$}45{\%}on latency. DiOMP offers a promising alternative to the traditional MPI+OpenMP hybrid programming model, towards providing a more productive and efficient way to develop high-performance parallel applications for distributed memory systems.",
isbn="978-3-031-72567-8"
}

@InProceedings{10.1007/978-3-031-72567-8_9,
abbr="LLVM/OpenMP",
author="Shan, Baodi
and Araya-Polo, Mauricio
and Chapman, Barbara",
editor="Espinosa, Alexis
and Klemm, Michael
and de Supinski, Bronis R.
and Cytowski, Maciej
and Klinkenberg, Jannis",
title="Evaluation of Directive-Based Programming Models for Stencil Computation on Current GPGPU Architectures",
booktitle="Advancing OpenMP for Future Accelerators",
year="2024",
publisher="Springer Nature Switzerland",
address="Cham",
pages="126--140",
abstract="Stencil calculations are a widely-used computing pattern, and tracking the performance of such computing pattern on modern GPGPUs is of interest to the computational community. In this document we focus on how directive-based programming models profit from the GPGPUs computing power and how they compare with the native programming model. One major takeaway is that OpenMP and OpenACC are still behind native code but closing the gap with newer generations of accelerators and SW stack. In particular, to address programmability we do compare the development effort of implementing optimized kernels with all the above mentioned programming models. Finally, we further extend the analysis to cover power consumption aspects, which complements the programming and performance perspectives.",
isbn="978-3-031-72567-8"
}




